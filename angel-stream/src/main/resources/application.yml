server:
  port: 8431
eureka:
  instance:
    metadata-map:
      user.name: angel
      user.password: angel
    health-check-url-path: /actuator/health
    ip-address: 127.0.0.1
    prefer-ip-address: true
    instance-id: ${eureka.instance.ip-address}:${server.port}
  client:
    registryFetchIntervalSeconds: 5
    serviceUrl:
      defaultZone: http://angel:angel@127.0.0.1:8123/eureka/    #注册中心地址，后面可配置服务集群
spring:
  datasource:
    druid:
      mysql:
        username: root
        password: root
        driver-class-name: com.mysql.jdbc.Driver
        url: jdbc:mysql://127.0.0.1:3306/angel?characterEncoding=utf8&zeroDateTimeBehavior=convertToNull&useSSL=false&useJDBCCompliantTimezoneShift=true&useLegacyDatetimeCode=false&serverTimezone=Asia/Shanghai
        initialSize: 5
        minIdle: 5
        maxActive: 20
  data:
    mongodb:    #引入mongodb
      url: mongodb://root:root@192.168.36.141:27017/angel
  application:
    name: angel-stream
  cloud:
    stream:
      instanceCount: 2   #指定当前的实例数为2
      instanceIndex: 0  #实例的索引号,从0开始
      binders:
        rabbitmq:      #这里集成了一个rabbitmq
          type: rabbit #集成rabbit
          environment: #配置rabbimq连接环境
            spring:
              rabbitmq:
                host: 127.0.0.1
                username: guest
                password: guest
                virtual-host: /
        kafka:       #集成kafka集群
          type: kafka
          environment:
            spring:
              cloud:
                stream:
                  kafka:
                    binder:
                      brokers: 192.168.36.141:9092
                      zkNodes: 192.168.36.141:2181   #zookeeper的地址
      bindings:
        rabbit_output: # 自定义的通道
          destination: myExchange  #exchange名称，交换模式默认是topic
          content-type: application/json
          binder: rabbitmq
          producer:
            partitionKeyExpression: payload
            partitionCount: 2
        rabbit_input:     ##消息接受者
          destination: myExchange
          content-type: application/json
          binder: rabbitmq
          group: rabbit-server-A   #分组的目的保证只能有一个消费者实例消费消息
          consumer:
            partitioned: true     #开启分组功能
        kafka_output:
          destination: kafka-Topic   #主题
          binder: kafka
          content-type: application/json
          producer:
            partitionKeyExpression: payload
            partitionCount: 2 #设置消费分区的数量
        kafka_input:
          destination: kafka-Topic   #主题
          content-type: application/json
          binder: kafka
          group: cloud-kafka-group
          autoCommitOffset: false
          consumer:
            partitioned: true  #设置分区






