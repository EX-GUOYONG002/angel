server:
  port: 8431
eureka:
  instance:
    metadata-map:
      user.name: angel
      user.password: angel
    health-check-url-path: /actuator/health
    ip-address: 127.0.0.1
    prefer-ip-address: true
    instance-id: ${eureka.instance.ip-address}:${server.port}
  client:
    registryFetchIntervalSeconds: 5
    serviceUrl:
      defaultZone: http://angel:angel@127.0.0.1:8123/eureka/    #注册中心地址，后面可配置服务集群
spring:
  application:
    name: angel-stream
  cloud:
    stream:
      instanceCount: 2   #指定当前的实例数为2
      instanceIndex: 0  #实例的索引号,从0开始
      binders:
        rabbitmq:      #这里集成了一个rabbitmq
          type: rabbit #集成rabbit
          environment: #配置rabbimq连接环境
            spring:
              rabbitmq:
                host: 127.0.0.1
                username: guest
                password: guest
                virtual-host: /
        kafka1:       #集成kafka集群
          type: kafka
          environment:
            spring:
              cloud:
                stream:
                  kafka:
                    binder:
                      brokers: 192.168.36.141:9092
                      zkNodes: 192.168.36.141:2181   #zookeeper的地址
        kafka2:       #集成kafka集群
          type: kafka
          environment:
            spring:
              cloud:
                stream:
                  kafka:
                    binder:
                      brokers: 192.168.36.141:9093
                      zkNodes: 192.168.36.141:2181   #zookeeper的地址
      bindings:
        rabbit_output: # 自定义的通道
          destination: myExchange  #exchange名称，交换模式默认是topic
          content-type: application/json
          binder: rabbitmq
          producer:
            partitionKeyExpression: payload
            partitionCount: 2
        rabbit_input:     ##消息接受者
          destination: myExchange
          content-type: application/json
          binder: rabbitmq
          group: rabbit-server-A   #分组的目的保证只能有一个消费者实例消费消息
          consumer:
            partitioned: true     #开启分组功能
        kafka_output1:
          destination: kafka-Topic-1   #主题
          binder: kafka1
          content-type: application/json
          producer:
            partitionKeyExpression: payload
            partitionCount: 2 #设置消费分区的数量
        kafka_output2:
          destination: kafka-Topic-2   #主题
          binder: kafka2
          content-type: application/json
          producer:
            partitionKeyExpression: payload
            partitionCount: 2 #设置消费分区的数量
        kafka_input1:
          destination: kafka-Topic-1   #主题
          content-type: application/json
          binder: kafka1
          group: cloud-kafka-group1
          autoCommitOffset: false
          consumer:
            partitioned: true  #设置分区
        kafka_input2:
          destination: kafka-Topic-2   #主题
          content-type: application/json
          binder: kafka2
          group: cloud-kafka-group2
          autoCommitOffset: false
          consumer:
            partitioned: true  #设置分区






